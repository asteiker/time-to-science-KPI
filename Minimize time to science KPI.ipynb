{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minus-vermont",
   "metadata": {},
   "source": [
    "# TRT KPI: Minimize Time to Science\n",
    "### *Number of lines of code for a given workflow in the cloud / Number of lines for same workflow on-prem\n",
    "### *Run time for a given workflow in the cloud / run time for same workflow on-prem\n",
    "\n",
    "#### Initial attempt: \n",
    "* Basic data search, customize, access, plotting, with a collection that is available on-prem and in Earthdata Cloud.\n",
    "* Initially, single ICESat-2 data product: ATL03 v003\n",
    "  * C1234714691-EEDTEST -> Harmony-enabled, UAT\n",
    "  * C1233596099-NSIDC_TS1 -> EGI-enabled, UAT\n",
    "* Bonus: Coincident data search/access/plot with another product\n",
    "* Bonus: Different data access options beyond Harmony (direct s3, cloudfront, OPeNDAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-rochester",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "from getpass import getpass\n",
    "from platform import system\n",
    "from netrc import netrc\n",
    "from os.path import join, expanduser\n",
    "from urllib import request\n",
    "from http.cookiejar import CookieJar\n",
    "import json\n",
    "from pprint import pprint\n",
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import io\n",
    "import shutil\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cartopy\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "!{sys.executable} -m pip install intake #install intake into Python kernel\n",
    "import intake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-action",
   "metadata": {},
   "source": [
    "## __On Prem workflow__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-killing",
   "metadata": {},
   "source": [
    "### (1. Search by time and bounding box (attempt using cmr-python library))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-number",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %cd eo-metadata-tools/CMR/python\n",
    "# #!{sys.executable} -m pip3 install wheel \n",
    "# #!{sys.executable} -m pip install wheel\n",
    "# #!{sys.executable} -m pip install https://github.com/nasa/eo-metadata-tools/releases/download/latest-master/eo_metadata_tools_cmr-0.0.1-py3-none-any.whl\n",
    "# %%bash\n",
    "# ./runme.sh -p -i\n",
    "\n",
    "# import cmr.search.granule as gran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-consultancy",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#gran.open_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-merchant",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import cmr.auth.token as t\n",
    "# import cmr.search.collection as coll\n",
    "\n",
    "# import platform\n",
    "# #print (\"Found in \" + platform.python_version())\n",
    "# import cmr.util.common as com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-israeli",
   "metadata": {},
   "source": [
    "This is starting to get complicated with the data behind an ACL. I can't get the bearer token to work here (and it involves going to URS and generating a token on my profile page - how would we time this?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-trigger",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# params = {}\n",
    "# #config = {'env':'uat'}\n",
    "# #params['provider'] = 'NSIDC_TS1'\n",
    "# params['collection_concept_id'] = 'C1233596099-NSIDC_TS1' \n",
    "# #params['bounding_box']= '-10,-5,10,5'\n",
    "# #results = gran.search(params, config=config)\n",
    "# results = gran.search(params, config=t.use_bearer_token(config={'env': 'uat'}))\n",
    "# print(\"Found {} records.\".format(len(results)))\n",
    "# for i in results:\n",
    "#     print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-recommendation",
   "metadata": {},
   "source": [
    "Back to the drawing board... trying the old fashioned way with the CMR API, and using https://github.com/podaac/AGU-2020/blob/main/Part-II/04_melt_pond/melt-pond-tutorial.ipynb as a framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-calvin",
   "metadata": {},
   "source": [
    "## __On Prem workflow__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather times to add up end to end\n",
    "onprem_times = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-surge",
   "metadata": {},
   "source": [
    "### 1. Authenticate against Earthdata Login\n",
    "\n",
    "#### Steps Involved:\n",
    "\n",
    "1. (Non-Code) Register an Earthdata Login Account\n",
    "1. (Non-Code) Verify Earthdata Login account\n",
    "1. (Non-Code) Add Earthdata Login credentials to .netrc file\n",
    "1. Set up code to authenticate if redirected to Earthdata Login **(Note: this is automatic if using the Python requests library.  This cell may not be actually used.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "def setup_earthdata_login_auth(endpoint: str='urs.uat.earthdata.nasa.gov'):\n",
    "    netrc_name = \"_netrc\" if system()==\"Windows\" else \".netrc\"\n",
    "    try:\n",
    "        username, _, password = netrc(file=join(expanduser('~'), netrc_name)).authenticators(endpoint)\n",
    "    except (FileNotFoundError, TypeError):\n",
    "        print('Please provide your Earthdata Login credentials for access.')\n",
    "        print('Your info will only be passed to %s and will not be exposed in Jupyter.' % (endpoint))\n",
    "        username = input('Username: ')\n",
    "        password = getpass('Password: ')\n",
    "    manager = request.HTTPPasswordMgrWithDefaultRealm()\n",
    "    manager.add_password(None, endpoint, username, password)\n",
    "    auth = request.HTTPBasicAuthHandler(manager)\n",
    "    jar = CookieJar()\n",
    "    processor = request.HTTPCookieProcessor(jar)\n",
    "    opener = request.build_opener(auth, processor)\n",
    "    request.install_opener(opener)\n",
    "    \n",
    "# Start authenticated session with URS to allow restricted data downloads:\n",
    "setup_earthdata_login_auth(endpoint=\"urs.uat.earthdata.nasa.gov\")\n",
    "wall_time = time.time() - t0\n",
    "onprem_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-robinson",
   "metadata": {},
   "source": [
    "### 2. Set up CMR token auth\n",
    "\n",
    "#### Steps Involved:\n",
    "\n",
    "5. Obtain Earthdata Login username and password in code\n",
    "1. Obtain own IP address (or decide to lie to CMR)\n",
    "1. Format username, password, and IP address to CMR XML format\n",
    "1. Perform token request against CMR\n",
    "1. Parse token request output to obtain the token as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "TOKEN_DATA = (\"<token>\"\n",
    "              \"<username>%s</username>\"\n",
    "              \"<password>%s</password>\"\n",
    "              \"<client_id>NSIDC TS1 Client</client_id>\"\n",
    "              \"<user_ip_address>%s</user_ip_address>\"\n",
    "              \"</token>\")\n",
    "\n",
    "\n",
    "def setup_cmr_token_auth(endpoint: str='cmr.uat.earthdata.nasa.gov'):\n",
    "    ip = requests.get(\"https://ipinfo.io/ip\").text.strip()\n",
    "    return requests.post(\n",
    "        url=\"https://%s/legacy-services/rest/tokens\" % endpoint,\n",
    "        data=TOKEN_DATA % (input(\"Username: \"), getpass(\"Password: \"), ip),\n",
    "        headers={'Content-Type': 'application/xml', 'Accept': 'application/json'}\n",
    "    ).json()['token']['id']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get your authentication token for searching restricted records in the CMR:\n",
    "_token = setup_cmr_token_auth(endpoint=\"cmr.uat.earthdata.nasa.gov\")\n",
    "wall_time = time.time() - t0\n",
    "onprem_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-password",
   "metadata": {},
   "source": [
    "### 3. Declare time and bounding box search parameters\n",
    "\n",
    "_Using a bounding box that will cover granules in EEDTEST (limiting factor compared to data in TS1)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-binding",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "10. Format desired spatial bounding box into CMR query format\n",
    "1. Format desired temporal range into CMR query format\n",
    "1. (Non-Code) Determine precise data product short name (perhaps already known by users)\n",
    "1. Set data product short name in code\n",
    "1. (Non-Code) Determine precise data product version identifier, including leading zeroes\n",
    "1. Set data product version identifier in code\n",
    "1. (Non-Code) Determine data provider identifier for the collection owner\n",
    "1. Set data provider identifier in code\n",
    "\n",
    "##### Alternative for 12-17\n",
    "\n",
    "12. (Non-Code) Go to Earthdata Search\n",
    "1. (Non-Code) Search for data product short name or similar\n",
    "1. (Non-Code) Select correct collection, revealing CMR Concept ID\n",
    "1. Copy/paste the CMR Concept ID into code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "# Bounding Box spatial parameter in decimal degree 'W,S,E,N' format.\n",
    "bounding_box = '-13.1,-72.7,114.5,-65.5'\n",
    "\n",
    "# Each date in yyyy-MM-ddTHH:mm:ssZ format; date range in start,end format\n",
    "temporal = '2020-01-01T00:00:00Z,2020-02-10T23:59:59Z'\n",
    "\n",
    "search_parameters= {'short_name': 'ATL03',\n",
    "               'version': '003', \n",
    "               'provider': 'NSIDC_TS1',\n",
    "               'bounding_box': bounding_box,\n",
    "               'temporal': temporal,\n",
    "                   }\n",
    "wall_time = time.time() - t0\n",
    "onprem_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-possibility",
   "metadata": {},
   "source": [
    "### 4. Search for granules based on time and bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-palace",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "**Assumption:** The user's desired results are contained on the first page of results, but larger than the default (10)\n",
    "\n",
    "18. Set the token as a request parameter\n",
    "1. Set desired CMR output format (using the default requires more steps to get at the desired information)\n",
    "1. Set the CMR page size to be large enough to contain all results\n",
    "1. Perform CMR granule search using provided parameters\n",
    "1. Parse the search result\n",
    "1. Retrieve granule records from the search result (Note: I break this out because it's relatively hard to get at)\n",
    "\n",
    "##### Skipped steps (not strictly necessary)\n",
    "* Error checking\n",
    "* Hits reporting\n",
    "* Set CMR parameter to scroll results (code does not go past the first page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "def search_granules(search_parameters, token, geojson=None, output_format=\"json\"):\n",
    "    \"\"\"\n",
    "    Performs a granule search with token authentication for restricted results\n",
    "    \n",
    "    :search_parameters: dictionary of CMR search parameters\n",
    "    :token: CMR token needed for restricted search\n",
    "    :geojson: filepath to GeoJSON file for spatial search\n",
    "    :output_format: select format for results https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#supported-result-formats\n",
    "    \n",
    "    :returns: if hits is greater than 0, search results are returned in chosen output_format, otherwise returns None.\n",
    "    \"\"\"\n",
    "    search_url = \"https://cmr.uat.earthdata.nasa.gov/search/granules\"\n",
    "    \n",
    "    # add token to search parameters\n",
    "    search_parameters['token'] = token\n",
    "    \n",
    "    if geojson:\n",
    "        files = {\"shapefile\": (geojson, open(geojson, \"r\"), \"application/geo+json\")}\n",
    "    else:\n",
    "        files = None\n",
    "    \n",
    "    \n",
    "    parameters = {\n",
    "        \"scroll\": \"true\",\n",
    "        \"page_size\": 100,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{search_url}.{output_format}\", params=parameters, data=search_parameters, files=files)\n",
    "        response.raise_for_status()\n",
    "    except HTTPError as http_err:\n",
    "        print(f\"HTTP Error: {http_error}\")\n",
    "    except Exception as err:\n",
    "        print(f\"Error: {err}\")\n",
    "    \n",
    "    hits = int(response.headers['CMR-Hits'])\n",
    "    if hits > 0:\n",
    "        print(f\"Found {hits} files\")\n",
    "        results = json.loads(response.content)\n",
    "        granules = []\n",
    "        granules.extend(results['feed']['entry'])\n",
    "        granule_sizes = [float(granule['granule_size']) for granule in granules]\n",
    "        print(f\"The total size of all files is {sum(granule_sizes):.2f} MB\")\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Found no hits\")\n",
    "        return\n",
    "\n",
    "search_granules(search_parameters, _token)\n",
    "wall_time = time.time() - t0\n",
    "onprem_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-appointment",
   "metadata": {},
   "source": [
    "### 5. Determine subsetting service options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-merit",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "24. Set the token as a request parameter\n",
    "1. Set desired CMR output format for collections (using the default requires more steps to get at the desired information)\n",
    "1. Perform CMR collection search using the collection-related search fields\n",
    "1. Parse the search result\n",
    "1. Retrieve collection from the search result\n",
    "1. Retrieve associated service IDs from the collection\n",
    "1. Set desired (different) output format for services\n",
    "1. Format a query to fetch the service for each service ID (why isn't this a link relation?)\n",
    "1. Perform CMR service search for each each service ID\n",
    "1. Parse the search result\n",
    "1. Retrieve service from the search result\n",
    "1. Retrieve associated service options from the service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "def search_services(search_parameters, token, output_format=\"json\"):\n",
    "    \"\"\"\n",
    "    Performs a granule search with token authentication for restricted results\n",
    "    \n",
    "    :search_parameters: dictionary of CMR search parameters\n",
    "    :token: CMR token needed for restricted search\n",
    "    :output_format: select format for results https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#supported-result-formats\n",
    "    \n",
    "    :returns: if hits is greater than 0, search results are returned in chosen output_format, otherwise returns None.\n",
    "    \"\"\"\n",
    "    collection_url = \"https://cmr.uat.earthdata.nasa.gov/search/collections\"\n",
    "    \n",
    "    # add token to search parameters\n",
    "    search_parameters['token'] = token\n",
    "    \n",
    "    parameters = {\n",
    "        \"scroll\": \"true\",\n",
    "        \"page_size\": 100,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{collection_url}.{output_format}\", params=parameters, data=search_parameters)\n",
    "        response.raise_for_status()\n",
    "    except HTTPError as http_err:\n",
    "        print(f\"HTTP Error: {http_error}\")\n",
    "    except Exception as err:\n",
    "        print(f\"Error: {err}\")\n",
    "    \n",
    "    hits = int(response.headers['CMR-Hits'])\n",
    "    if hits > 0:\n",
    "        response = response.json()\n",
    "        if 'services' in response['feed']['entry'][0]['associations']: \n",
    "            services = response['feed']['entry'][0]['associations']['services']\n",
    "            output_format = \"umm_json\"\n",
    "            service_url = \"https://cmr.uat.earthdata.nasa.gov/search/services\"\n",
    "            for i in range(len(services)):\n",
    "                response = requests.get(f\"{service_url}.{output_format}?concept-id={services[i]}\")\n",
    "                response = response.json()\n",
    "                if 'ServiceOptions' in response['items'][0]['umm']: pprint(response['items'][0]['umm']['ServiceOptions'])\n",
    "        else:\n",
    "            print(\"Found no services\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"Found no hits\")\n",
    "        return\n",
    "\n",
    "search_services(search_parameters, _token)\n",
    "wall_time = time.time() - t0\n",
    "onprem_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-insulin",
   "metadata": {},
   "source": [
    "### 6. Determine variables\n",
    "\n",
    "_Today there are no UMM-Var records for the on-prem collection_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-olympus",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-textbook",
   "metadata": {},
   "source": [
    "#### 7. Determine variables: Authenticate against EGI endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-archive",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "36. (External) Determine EGI URL and format\n",
    "1. Format EGI capabilities URL with collection short name and version\n",
    "1. Perform EGI capabilities GET request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "uid = input('Earthdata Login user name: ') # Enter Earthdata Login user name\n",
    "pswd = getpass('Earthdata Login password: ') # Enter Earthdata Login password\n",
    "\n",
    "# Query service capability URL \n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "capability_url = f'https://n5eil12u.ecs.nsidc.org/egi_TS1/capabilities/{search_parameters[\"short_name\"]}.{search_parameters[\"version\"]}.xml'\n",
    "\n",
    "# Create session to store cookie and pass credentials to capabilities url\n",
    "\n",
    "session = requests.session()\n",
    "s = session.get(capability_url)\n",
    "response = session.get(s.url,auth=(uid,pswd))\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "onprem_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-license",
   "metadata": {},
   "source": [
    "#### 8. Determine variables: Query EGI for variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-adventure",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "39. Parse the EGI response\n",
    "1. Locate each variable in the response\n",
    "1. Extract the variable name from each variable\n",
    "1. Ensure that each variable starts with a leading '/', inserting it if not **(Note: output looks buggy)**\n",
    "1. Replace ':' with '/' in variable names to form more conventional variable paths\n",
    "1. Locate each format option in the response\n",
    "1. Extract the format name from each format\n",
    "1. Remove empty formats that were returned\n",
    "1. Locate each projection option in the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "root = ET.fromstring(response.content)\n",
    "\n",
    "#collect lists with each service option\n",
    "\n",
    "subagent = [subset_agent.attrib for subset_agent in root.iter('SubsetAgent')]\n",
    "if len(subagent) > 0 :\n",
    "\n",
    "    # variable subsetting\n",
    "    variables = [SubsetVariable.attrib for SubsetVariable in root.iter('SubsetVariable')]  \n",
    "    variables_raw = [variables[i]['value'] for i in range(len(variables))]\n",
    "    variables_join = [''.join(('/',v)) if v.startswith('/') == False else v for v in variables_raw] \n",
    "    variable_vals = [v.replace(':', '/') for v in variables_join]\n",
    "\n",
    "    # reformatting\n",
    "    formats = [Format.attrib for Format in root.iter('Format')]\n",
    "    format_vals = [formats[i]['value'] for i in range(len(formats))]\n",
    "    format_vals.remove('')\n",
    "\n",
    "    # reprojection options\n",
    "    projections = [Projection.attrib for Projection in root.iter('Projection')]\n",
    "    \n",
    "print(variable_vals)\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "onprem_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-chick",
   "metadata": {},
   "source": [
    "### 9. Request variable subset\n",
    "\n",
    "_Starting with a variable subsetting request, since spatial subsetting for ICESat-2 is not available yet in the cloud. Alternatively we could attempt to spatially subset without services (i.e. subsetting using xarray)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-clothing",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "48. Select all desired variables and provide them in code\n",
    "1. (External) Determine URL format for an EGI subset request\n",
    "1. Format desired variables for a URL query string\n",
    "1. Construct URL using URL, temporal, variable, and spatial parameters from prior requests\n",
    "1. Specify additional bbox subset parameter to equal bounding box spatial filter from prior request  \n",
    "\n",
    "##### Notes\n",
    "* Assumes prior requests define formatted temporal and bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-camera",
   "metadata": {},
   "source": [
    "#### Request variable subset: Determine API request \n",
    "\n",
    "_This isn't really required so not including it as a step_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set NSIDC data access base URL\n",
    "base_url = 'https://n5eil12u.ecs.nsidc.org/egi_TS1/request'\n",
    "\n",
    "# bounding box search and subset:\n",
    "param_dict = {'short_name': 'ATL03', \n",
    "              'version': '003', \n",
    "              'temporal': temporal, \n",
    "              'bounding_box': bounding_box, \n",
    "              'bbox': bounding_box, \n",
    "              'coverage': '/gt1r/heights/h_ph,/gt1l/heights/h_ph,/gt2r/heights/h_ph,/gt2l/heights/h_ph,/gt1r/heights/lat_ph,/gt1l/heights/lat_ph,/gt2r/heights/lat_ph,/gt2l/heights/lat_ph,/gt1r/heights/lon_ph,/gt1l/heights/lon_ph,/gt2r/heights/lon_ph,/gt2l/heights/lon_ph',\n",
    "              'page_size': '10', \n",
    "              'request_mode': 'async',\n",
    "              'email': '',\n",
    "              'token' : _token,\n",
    "             }\n",
    "\n",
    "#Remove blank key-value-pairs\n",
    "param_dict = {k: v for k, v in param_dict.items() if v != ''}\n",
    "\n",
    "#Convert to string\n",
    "param_string = '&'.join(\"{!s}={!r}\".format(k,v) for (k,v) in param_dict.items())\n",
    "param_string = param_string.replace(\"'\",\"\")\n",
    "\n",
    "API_request = api_request = f'{base_url}?{param_string}'\n",
    "print(API_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-affairs",
   "metadata": {},
   "source": [
    "#### 10. Request variable subset: Download customized data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-trader",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "53. Create / allocate a location for downloaded files\n",
    "1. Perform subsetting HTTP request\n",
    "1. Parse subsetting response\n",
    "1. Extract order IDs from subsetting response\n",
    "1. (External) Determine how to construct a URL to get an order from the EGI API\n",
    "1. Construct an EGI order URL for the order ID\n",
    "1. Create a loop to repeatedly poll order status\n",
    "1. Perform the EGI request for the order\n",
    "1. Parse the order response\n",
    "1. Extract the order status from the response\n",
    "1. Test if the order is still processing, looping if so (end of loop)\n",
    "1. (External) Determine how to construct an EGI URL to fetch the results of an order\n",
    "1. Construct an EGI URL to fetch order results from the order ID\n",
    "1. Download the zip file of the order results\n",
    "1. Unzip the order results zip file\n",
    "\n",
    "##### Notes\n",
    "* Ignoring failed orders, not necessary for happy path\n",
    "* HTTP response code validation not included as not strictly necessary on the happy path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Create an output folder if the folder does not already exist.\n",
    "\n",
    "path = str(os.getcwd() + '/Outputs')\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "# For all requests other than spatial file upload, use get function\n",
    "request = session.get(base_url, params=param_dict)\n",
    "\n",
    "print('Request HTTP response: ', request.status_code)\n",
    "\n",
    "# Raise bad request: Loop will stop for bad response code.\n",
    "request.raise_for_status()\n",
    "print('Order request URL: ', request.url)\n",
    "esir_root = ET.fromstring(request.content)\n",
    "print('Order request response XML content: ', request.content)\n",
    "\n",
    "#Look up order ID\n",
    "orderlist = []   \n",
    "for order in esir_root.findall(\"./order/\"):\n",
    "    orderlist.append(order.text)\n",
    "orderID = orderlist[0]\n",
    "print('order ID: ', orderID)\n",
    "\n",
    "#Create status URL\n",
    "statusURL = base_url + '/' + orderID\n",
    "print('status URL: ', statusURL)\n",
    "\n",
    "#Find order status\n",
    "request_response = session.get(statusURL)    \n",
    "print('HTTP response from order response URL: ', request_response.status_code)\n",
    "\n",
    "# Raise bad request: Loop will stop for bad response code.\n",
    "request_response.raise_for_status()\n",
    "request_root = ET.fromstring(request_response.content)\n",
    "statuslist = []\n",
    "for status in request_root.findall(\"./requestStatus/\"):\n",
    "    statuslist.append(status.text)\n",
    "status = statuslist[0]\n",
    "print('Data request is submitting...')\n",
    "print('Initial request status is ', status)\n",
    "\n",
    "#Continue loop while request is still processing\n",
    "while status == 'pending' or status == 'processing': \n",
    "    print('Status is not complete. Trying again.')\n",
    "    time.sleep(10)\n",
    "    loop_response = session.get(statusURL)\n",
    "\n",
    "# Raise bad request: Loop will stop for bad response code.\n",
    "    loop_response.raise_for_status()\n",
    "    loop_root = ET.fromstring(loop_response.content)\n",
    "\n",
    "#find status\n",
    "    statuslist = []\n",
    "    for status in loop_root.findall(\"./requestStatus/\"):\n",
    "        statuslist.append(status.text)\n",
    "    status = statuslist[0]\n",
    "    print('Retry request status is: ', status)\n",
    "    if status == 'pending' or status == 'processing':\n",
    "        continue\n",
    "\n",
    "#Order can either complete, complete_with_errors, or fail:\n",
    "# Provide complete_with_errors error message:\n",
    "if status == 'complete_with_errors' or status == 'failed':\n",
    "    messagelist = []\n",
    "    for message in loop_root.findall(\"./processInfo/\"):\n",
    "        messagelist.append(message.text)\n",
    "    print('error messages:')\n",
    "    pprint.pprint(messagelist)\n",
    "\n",
    "# Download zipped order if status is complete or complete_with_errors\n",
    "if status == 'complete' or status == 'complete_with_errors':\n",
    "    downloadURL = 'https://n5eil12u.ecs.nsidc.org/esir_TS1/' + orderID + '.zip'\n",
    "    print('Zip download URL: ', downloadURL)\n",
    "    print('Beginning download of zipped output...')\n",
    "    zip_response = session.get(downloadURL)\n",
    "    # Raise bad request: Loop will stop for bad response code.\n",
    "    zip_response.raise_for_status()\n",
    "    with zipfile.ZipFile(io.BytesIO(zip_response.content)) as z:\n",
    "        z.extractall(path)\n",
    "    print('Data request is complete.')\n",
    "else: print('Request failed.')\n",
    "    \n",
    "wall_time = time.time() - t0\n",
    "onprem_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-blink",
   "metadata": {},
   "source": [
    "#### 11. Clean up Outputs folder by removing individual granule folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "for root, dirs, files in os.walk(path, topdown=False):\n",
    "    for file in files:\n",
    "        try:\n",
    "            shutil.move(os.path.join(root, file), path)\n",
    "        except OSError:\n",
    "            pass\n",
    "    for name in dirs:\n",
    "        os.rmdir(os.path.join(root, name))\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "onprem_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-rubber",
   "metadata": {},
   "source": [
    "### 12. Read in Data using h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "def load_icesat2_as_dataframe(filepath, VARIABLES):\n",
    "    '''\n",
    "    Load points from an ICESat-2 granule 'gt<beam>' groups as DataFrame of points. Uses VARIABLES mapping\n",
    "    to select subset of '/gt<beam>/...' variables  (Assumes these variables share dimensions)\n",
    "    Arguments:\n",
    "        filepath to ATL0# granule\n",
    "    '''\n",
    "    \n",
    "    ds = h5py.File(filepath, 'r')\n",
    "\n",
    "    # Get dataproduct name\n",
    "    dataproduct = ds.attrs['identifier_product_type'].decode()\n",
    "    # Convert variable paths to 'Path' objects for easy manipulation\n",
    "    variables = [Path(v) for v in VARIABLES[dataproduct]]\n",
    "    # Get set of beams to extract individially as dataframes combining in the end\n",
    "    beams = {list(v.parents)[-2].name for v in variables}\n",
    "    \n",
    "    dfs = []\n",
    "    for beam in beams:\n",
    "        data_dict = {}\n",
    "        beam_variables = [v for v in variables if beam in str(v)]\n",
    "        for variable in beam_variables:\n",
    "            # Use variable 'name' as column name. Beam will be specified in 'beam' column\n",
    "            column = variable.name\n",
    "            variable = str(variable)\n",
    "            try:\n",
    "                values = ds[variable][:]\n",
    "                # Convert invalid data to np.nan (only for float columns)\n",
    "                if 'float' in str(values.dtype):\n",
    "                    if 'valid_min' in ds[variable].attrs:\n",
    "                        values[values < ds[variable].attrs['valid_min']] = np.nan\n",
    "                    if 'valid_max' in ds[variable].attrs:\n",
    "                        values[values > ds[variable].attrs['valid_max']] = np.nan\n",
    "                    if '_FillValue' in ds[variable].attrs:\n",
    "                        values[values == ds[variable].attrs['_FillValue']] = np.nan\n",
    "                    \n",
    "                data_dict[column] = values\n",
    "            except KeyError:\n",
    "                print(f'Variable {variable} not found in {filepath}. Likely an empty granule.')\n",
    "                raise\n",
    "                \n",
    "        df = pd.DataFrame.from_dict(data_dict)\n",
    "        df['beam'] = beam\n",
    "        dfs.append(df)\n",
    "        \n",
    "    df = pd.concat(dfs, sort=True)\n",
    "    # Add filename column for book-keeping and reset index\n",
    "    df['filename'] = Path(filepath).name\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "onprem_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-audio",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "68. Loop over each resulting data file (Not done in this code, but would be needed in a general case)\n",
    "1. Open the result using h5py\n",
    "1. Loop over each variable of interest\n",
    "1. Correct for flag values not handled by h5py in each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "atl_filepath = './Outputs/processed_ATL03_20200131230704_05530610_003_01.h5' # Define local filepath \n",
    "\n",
    "VARIABLES = {\n",
    "    'ATL03': [\n",
    "        '/gt1l/heights/h_ph',\n",
    "        '/gt1r/heights/h_ph',\n",
    "        '/gt2l/heights/h_ph',\n",
    "        '/gt2r/heights/h_ph',\n",
    "        '/gt1l/heights/lat_ph',\n",
    "        '/gt1r/heights/lat_ph',\n",
    "        '/gt2l/heights/lat_ph',\n",
    "        '/gt2r/heights/lat_ph',\n",
    "        '/gt1l/heights/lon_ph',\n",
    "        '/gt1r/heights/lon_ph',\n",
    "        '/gt2l/heights/lon_ph',\n",
    "        '/gt2r/heights/lon_ph',\n",
    "        ]\n",
    "}\n",
    "\n",
    "atl03 = load_icesat2_as_dataframe(atl_filepath, VARIABLES)\n",
    "print(atl03.tail())\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "onprem_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-coating",
   "metadata": {},
   "source": [
    "### 13. Plot data\n",
    "\n",
    "**Due to the # of data values, the plotting is compute-intensive and may take several minutes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-leadership",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "72. Plot each variable (collapsed as incomplete, use-case-specific, and generally just necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "plt.figure(figsize=(10,8), dpi= 90)\n",
    "ax = plt.axes(projection=ccrs.SouthPolarStereo(central_longitude=0)) \n",
    "ax.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "ax.set_extent([-180, 180, -65, -90], ccrs.PlateCarree())\n",
    "plt.scatter(atl03.lon_ph,\n",
    "            atl03.lat_ph,\n",
    "            c=atl03.h_ph,\n",
    "            cmap='viridis',\n",
    "            vmin=100,vmax=200,\n",
    "            transform=ccrs.PlateCarree())\n",
    "plt.colorbar(label='elevation', shrink=0.5, extend='both')\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "onprem_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-ambassador",
   "metadata": {},
   "source": [
    "## Total on-prem time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total on prem time (sec):\", sum(onprem_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-arthur",
   "metadata": {},
   "source": [
    "## __Cloud workflow__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather times to add up end to end\n",
    "cloud_times = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-affect",
   "metadata": {},
   "source": [
    "### 1. Set up CMR token auth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-chapel",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "1. (Non-Code) Register an Earthdata Login Account\n",
    "1. (Non-Code) Verify Earthdata Login account\n",
    "1. Obtain Earthdata Login username and password in code\n",
    "1. Obtain own IP address (or decide to lie to CMR)\n",
    "1. Format username, password, and IP address to CMR XML format\n",
    "1. Perform token request against CMR\n",
    "1. Parse token request output to obtain the token as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "TOKEN_DATA = (\"<token>\"\n",
    "              \"<username>%s</username>\"\n",
    "              \"<password>%s</password>\"\n",
    "              \"<client_id>NSIDC TS1 Client</client_id>\"\n",
    "              \"<user_ip_address>%s</user_ip_address>\"\n",
    "              \"</token>\")\n",
    "\n",
    "\n",
    "def setup_cmr_token_auth(endpoint: str='cmr.uat.earthdata.nasa.gov'):\n",
    "    ip = requests.get(\"https://ipinfo.io/ip\").text.strip()\n",
    "    return requests.post(\n",
    "        url=\"https://%s/legacy-services/rest/tokens\" % endpoint,\n",
    "        data=TOKEN_DATA % (input(\"Username: \"), getpass(\"Password: \"), ip),\n",
    "        headers={'Content-Type': 'application/xml', 'Accept': 'application/json'}\n",
    "    ).json()['token']['id']\n",
    "\n",
    "\n",
    "# Get your authentication token for searching restricted records in the CMR:\n",
    "_token = setup_cmr_token_auth(endpoint=\"cmr.uat.earthdata.nasa.gov\")\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "cloud_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-bowling",
   "metadata": {},
   "source": [
    "### 2. Declare time and bounding box search parameters\n",
    "\n",
    "_Using a bounding box that will cover granules in EEDTEST (limiting factor compared to data in TS1)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-scenario",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "8. Format desired spatial bounding box into CMR query format\n",
    "1. Format desired temporal range into CMR query format\n",
    "1. (Non-Code) Determine precise data product short name (perhaps already known by users)\n",
    "1. Set data product short name in code\n",
    "1. (Non-Code) Determine precise data product version identifier, including leading zeroes\n",
    "1. Set data product version identifier in code\n",
    "1. (Non-Code) Determine data provider identifier for the collection owner\n",
    "1. Set data provider identifier in code\n",
    "\n",
    "##### Alternative for 12-17\n",
    "\n",
    "10. (Non-Code) Go to Earthdata Search\n",
    "1. (Non-Code) Search for data product short name or similar\n",
    "1. (Non-Code) Select correct collection, revealing CMR Concept ID\n",
    "1. Copy/paste the CMR Concept ID into code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Bounding Box spatial parameter in decimal degree 'W,S,E,N' format.\n",
    "bounding_box = '-13.1,-72.7,114.5,-65.5'\n",
    "\n",
    "# Each date in yyyy-MM-ddTHH:mm:ssZ format; date range in start,end format\n",
    "temporal = '2020-01-01T00:00:00Z,2020-02-10T23:59:59Z'\n",
    "\n",
    "search_parameters= {'short_name': 'ATL03VARSUBSETTER',\n",
    "               'version': '003', \n",
    "               #'concept_id':'C1234714691-EEDTEST',\n",
    "               'provider': 'EEDTEST',\n",
    "               'bounding_box': bounding_box,\n",
    "               'temporal': temporal,\n",
    "                   }\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "cloud_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-entrepreneur",
   "metadata": {},
   "source": [
    "### 3. Search for granules based on time and bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-worship",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "**Assumption:** The user's desired results are contained on the first page of results, but larger than the default (10)\n",
    "\n",
    "16. Set the token as a request parameter\n",
    "1. Set desired CMR output format (using the default requires more steps to get at the desired information)\n",
    "1. Set the CMR page size to be large enough to contain all results\n",
    "1. Perform CMR granule search using provided parameters\n",
    "1. Parse the search result\n",
    "1. Retrieve granule records from the search result (Note: I break this out because it's relatively hard to get at)\n",
    "\n",
    "##### Skipped steps (not strictly necessary)\n",
    "* Error checking\n",
    "* Hits reporting\n",
    "* Set CMR parameter to scroll results (code does not go past the first page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "def search_granules(search_parameters, token, geojson=None, output_format=\"json\"):\n",
    "    \"\"\"\n",
    "    Performs a granule search with token authentication for restricted results\n",
    "    \n",
    "    :search_parameters: dictionary of CMR search parameters\n",
    "    :token: CMR token needed for restricted search\n",
    "    :geojson: filepath to GeoJSON file for spatial search\n",
    "    :output_format: select format for results https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#supported-result-formats\n",
    "    \n",
    "    :returns: if hits is greater than 0, search results are returned in chosen output_format, otherwise returns None.\n",
    "    \"\"\"\n",
    "    search_url = \"https://cmr.uat.earthdata.nasa.gov/search/granules\"\n",
    "    \n",
    "    # add token to search parameters\n",
    "    search_parameters['token'] = token\n",
    "    \n",
    "    if geojson:\n",
    "        files = {\"shapefile\": (geojson, open(geojson, \"r\"), \"application/geo+json\")}\n",
    "    else:\n",
    "        files = None\n",
    "    \n",
    "    \n",
    "    parameters = {\n",
    "        \"scroll\": \"true\",\n",
    "        \"page_size\": 100,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{search_url}.{output_format}\", params=parameters, data=search_parameters, files=files)\n",
    "        response.raise_for_status()\n",
    "    except HTTPError as http_err:\n",
    "        print(f\"HTTP Error: {http_error}\")\n",
    "    except Exception as err:\n",
    "        print(f\"Error: {err}\")\n",
    "    \n",
    "    hits = int(response.headers['CMR-Hits'])\n",
    "    if hits > 0:\n",
    "        print(f\"Found {hits} files\")\n",
    "        results = json.loads(response.content)\n",
    "        granules = []\n",
    "        granules.extend(results['feed']['entry'])\n",
    "        granule_sizes = [float(granule['granule_size']) for granule in granules]\n",
    "        print(f\"The total size of all files is {sum(granule_sizes):.2f} MB\")\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Found no hits\")\n",
    "        return\n",
    "\n",
    "search_granules(search_parameters, _token)\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "cloud_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-auction",
   "metadata": {},
   "source": [
    "### 4. Determine subsetting service options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-satellite",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "22. Set the token as a request parameter\n",
    "1. Set desired CMR output format for collections (using the default requires more steps to get at the desired information)\n",
    "1. Perform CMR collection search using the collection-related search fields\n",
    "1. Parse the search result\n",
    "1. Retrieve collection from the search result\n",
    "1. Retrieve associated service IDs from the collection\n",
    "1. Set desired (different) output format for services\n",
    "1. Format a query to fetch the service for each service ID (why isn't this a link relation?)\n",
    "1. Perform CMR service search for each each service ID\n",
    "1. Parse the search result\n",
    "1. Retrieve service from the search result\n",
    "1. Retrieve associated service options from the service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "def search_services(search_parameters, token, output_format=\"json\"):\n",
    "    \"\"\"\n",
    "    Performs a granule search with token authentication for restricted results\n",
    "    \n",
    "    :search_parameters: dictionary of CMR search parameters\n",
    "    :token: CMR token needed for restricted search\n",
    "    :output_format: select format for results https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#supported-result-formats\n",
    "    \n",
    "    :returns: if hits is greater than 0, search results are returned in chosen output_format, otherwise returns None.\n",
    "    \"\"\"\n",
    "    collection_url = \"https://cmr.uat.earthdata.nasa.gov/search/collections\"\n",
    "    \n",
    "    # add token to search parameters\n",
    "    search_parameters['token'] = token\n",
    "    \n",
    "    parameters = {\n",
    "        \"scroll\": \"true\",\n",
    "        \"page_size\": 100,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{collection_url}.{output_format}\", params=parameters, data=search_parameters)\n",
    "        response.raise_for_status()\n",
    "    except HTTPError as http_err:\n",
    "        print(f\"HTTP Error: {http_error}\")\n",
    "    except Exception as err:\n",
    "        print(f\"Error: {err}\")\n",
    "    \n",
    "    hits = int(response.headers['CMR-Hits'])\n",
    "    if hits > 0:\n",
    "        response = response.json()\n",
    "        if 'services' in response['feed']['entry'][0]['associations']: \n",
    "            services = response['feed']['entry'][0]['associations']['services']\n",
    "            output_format = \"umm_json\"\n",
    "            service_url = \"https://cmr.uat.earthdata.nasa.gov/search/services\"\n",
    "            for i in range(len(services)):\n",
    "                response = requests.get(f\"{service_url}.{output_format}?concept-id={services[i]}\")\n",
    "                response = response.json()\n",
    "                if 'ServiceOptions' in response['items'][0]['umm']: pprint(response['items'][0]['umm']['ServiceOptions'])\n",
    "        else:\n",
    "            print(\"Found no services\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"Found no hits\")\n",
    "        return\n",
    "\n",
    "search_services(search_parameters, _token)\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "cloud_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-stocks",
   "metadata": {},
   "source": [
    "### 5. Determine variables\n",
    "\n",
    "_Can use UMM-Var to return cleaner Long Names, and Name value needed for Harmony request_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-energy",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "34. Retrieve associated variable IDs from the collection\n",
    "1. Set desired (different) output format for variables\n",
    "1. Format a query to fetch the service for each variable ID (why isn't this a link relation?)\n",
    "1. Perform CMR variable search for each variable ID\n",
    "1. Parse the search result\n",
    "1. Retrieve variable from the search result\n",
    "1. Retrieve variable names from the variable\n",
    "\n",
    "##### Notes\n",
    "* Assumes we could reuse the already-searched and parsed collection record from service lookup step with refactoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "def search_vars(search_parameters, token, output_format=\"json\"):\n",
    "    \"\"\"\n",
    "    Performs a granule search with token authentication for restricted results\n",
    "    \n",
    "    :search_parameters: dictionary of CMR search parameters\n",
    "    :token: CMR token needed for restricted search\n",
    "    :output_format: select format for results https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#supported-result-formats\n",
    "    \n",
    "    :returns: if hits is greater than 0, search results are returned in chosen output_format, otherwise returns None.\n",
    "    \"\"\"\n",
    "    collection_url = \"https://cmr.uat.earthdata.nasa.gov/search/collections\"\n",
    "    \n",
    "    # add token to search parameters\n",
    "    search_parameters['token'] = token\n",
    "    \n",
    "    parameters = {\n",
    "        \"scroll\": \"true\",\n",
    "        \"page_size\": 100,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{collection_url}.{output_format}\", params=parameters, data=search_parameters)\n",
    "        response.raise_for_status()\n",
    "    except HTTPError as http_err:\n",
    "        print(f\"HTTP Error: {http_error}\")\n",
    "    except Exception as err:\n",
    "        print(f\"Error: {err}\")\n",
    "    \n",
    "    hits = int(response.headers['CMR-Hits'])\n",
    "    if hits > 0:\n",
    "        response = response.json()\n",
    "        if 'variables' in response['feed']['entry'][0]['associations']: \n",
    "            variables = response['feed']['entry'][0]['associations']['variables']\n",
    "            output_format = \"umm_json\"\n",
    "            var_url = \"https://cmr.uat.earthdata.nasa.gov/search/variables\"\n",
    "            for i in range(len(variables)):\n",
    "                response = requests.get(f\"{var_url}.{output_format}?concept-id={variables[i]}\")\n",
    "                response = response.json()\n",
    "                if 'LongName' in response['items'][0]['umm']: \n",
    "                    pprint(response['items'][0]['umm']['LongName'])\n",
    "                    pprint(response['items'][0]['umm']['Name'])\n",
    "        else:\n",
    "            print(\"Found no services\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"Found no hits\")\n",
    "        return\n",
    "\n",
    "search_vars(search_parameters, _token)\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "cloud_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-journalism",
   "metadata": {},
   "source": [
    "### 6. Request variable subset\n",
    "\n",
    "_Starting with a variable subsetting request, since spatial subsetting for ICESat-2 is not available yet in the cloud. Alternatively we could attempt to spatially subset without services (i.e. subsetting using xarray)_\n",
    "\n",
    "_Using Harmony-py, this is a few easy lines of code_\n",
    "\n",
    "**Note that the exact same variables are not curated in umm-var compared to what was requested on-prem. For plotting purposes, 1 extra var is included on-prem for  **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-statistics",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "41. Install harmony-py\n",
    "1. Import harmony-py libraries\n",
    "1. Create Harmony client with previously obtained auth (or set up / use .netrc)\n",
    "1. Construct Harmony request object using desired spatial / temporal / variables\n",
    "1. Submit the Harmony request, obtaining a Job ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "!{sys.executable} -m pip install -U harmony-py #install harmony-py into Python kernel\n",
    "import sys; sys.path.append('..')\n",
    "import datetime as dt\n",
    "from IPython.display import display, JSON\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "\n",
    "from harmony import BBox, Client, Collection, Request\n",
    "from harmony.config import Environment\n",
    "\n",
    "harmony_client = Client(auth=('uid', 'pwd'), env=Environment.UAT)\n",
    "request = Request(\n",
    "    collection=Collection(id='ATL03VARSUBSETTER'),\n",
    "    spatial=BBox(-13.1,-72.7,114.5,-65.5),\n",
    "    temporal={\n",
    "        'start': dt.datetime(2020, 1, 1),\n",
    "        'stop': dt.datetime(2020, 2, 10)\n",
    "    },    \n",
    "    variables=['/gt1r/signal_find_output/ocean/bckgrd_mean',\n",
    "        '/gt1r/geolocation/reference_photon_lat',\n",
    "        '/gt1r/geophys_corr/geoid',\n",
    "        '/gt1r/heights/lat_ph',\n",
    "        '/gt1r/heights/h_ph',\n",
    "        '/gt1r/heights/lon_ph',\n",
    "        '/gt1r/bckgrd_atlas/bckgrd_counts',\n",
    "        '/gt1r/geolocation/reference_photon_lon',\n",
    "        '/orbit_info/orbit_number',\n",
    "        '/gt1r/geolocation/altitude_sc',\n",
    "        '/gt1r/geolocation/ph_index_beg',\n",
    "        ]\n",
    ")\n",
    "job_id = harmony_client.submit(request)\n",
    "print(job_id)\n",
    "#results = harmony_client.download_all(job_id, directory='/tmp', overwrite=True)\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "cloud_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-transfer",
   "metadata": {},
   "source": [
    "### 7. Retrieve AWS Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-termination",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "46. Obtain AWS Credentials for in-region use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "creds = harmony_client.aws_credentials()\n",
    "print(creds)\n",
    "\n",
    "wall_time = time.time() - t0\n",
    "cloud_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-shopping",
   "metadata": {},
   "source": [
    "### 8. Plot data in place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-batman",
   "metadata": {},
   "source": [
    "#### Steps Involved:\n",
    "\n",
    "47. Obtain STAC catalog URL for job ID\n",
    "1. Iterate over each STAC asset\n",
    "1. Plot the asset (For parity with on-prem visualization is collapsed into a single step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "\n",
    "# stac_catalog_url = harmony_client.stac_catalog_url(job_id)\n",
    "# print(stac_catalog_url)\n",
    "\n",
    "# wall_time = time.time() - t0\n",
    "# cloud_times.append(wall_time)\n",
    "# print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# NOTE: Execution of this cell will only succeed within the AWS us-west-2 region. \n",
    "#\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "stac_catalog_url = harmony_client.stac_catalog_url(job_id)\n",
    "print(stac_catalog_url)\n",
    "cat = intake.open_stac_catalog(stac_catalog_url)\n",
    "display(list(cat))\n",
    "for i in range(len(list(cat))):\n",
    "    da = cat[list(cat)[i]][entries[i].describe()['name']].to_dask()\n",
    "    display(da)\n",
    "    da.plot()\n",
    "    \n",
    "wall_time = time.time() - t0\n",
    "cloud_times.append(wall_time)\n",
    "print (wall_time, \"seconds wall time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-intention",
   "metadata": {},
   "source": [
    "## Total cloud time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total cloud time (sec):\", sum(cloud_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-fluid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsidc-cloud",
   "language": "python",
   "name": "nsidc-cloud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
